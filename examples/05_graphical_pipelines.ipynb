{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Graphical Pipelines\n",
    "\n",
    "The previously presented pipelines are sequential pipelines. I.e., the steps in the pipeline are sequentially ordered. To enable more complex tasks, these pipelines could be nested into each other. However, this makes it difficult to apply a grid search to the pipeline. Furthermore, the nesting of pipelines is not very intuitive and makes it difficult to understand the pipeline. Thus, we also propose a generalised graphical pipeline.\n",
    "* Graphical means that the pipeline is not sequential anymore. Instead, the pipeline is a directed acyclic graph (DAG). This means that the pipeline consists of nodes and edges. The nodes are the steps in the pipeline and the edges are the connections between the steps. The edges specify the input and output arguments of the steps. Thus, the graphical pipeline is a generalisation of the sequential pipeline.\n",
    "* Generalised means that the pipeline is not limited to one task (e.g. forecasting). Instead, the generalised graphical pipeline is applicable for various tasks, e.g., forecasting, classification, and regression. Moreover, this also enables the combination of different tasks in one pipeline. E.g., a pipeline could consist of a regression steps and a classification step.\n",
    "\n",
    "Note that the graphical pipeline is still experimental. Thus, this graphical should not used in production. However, we would be happy to get feedback on the graphical pipeline.\n",
    "\n",
    "\n",
    "\n",
    "### Potential Use-Cases\n",
    "There exist various potential use-case for the graphical pipeline. In the following, we focus on a forecasting and a classification pipeline.\n",
    "#### Forecasting Use-Case for Graphical Pipelines\n",
    "In forecasting tasks, the input of forecasters might depend on the output of other forecasters for exogenous variables. These forecasters for exogenous variables might share the same input arguments. Thus, there is a branching of the data flow since the same input is used for different forecasters. Afterwards, if the output of the forecasters are combined, there is a merging of the data flow.\n",
    "Thus, the graphical pipeline is a natural fit for such forecasting tasks. Furthermore, the graphical pipeline enables the combination of different forecasters in one pipeline. E.g., a pipeline could consist of a forecaster that forecasts the trend and a forecaster that forecasts the seasonality.\n",
    "Integrating this in a graphical pipeline makes it easier to understand the pipeline and to apply a grid search to the pipeline.\n",
    "\n",
    "#### Classification Use-Case for Graphical Pipelines\n",
    "\n",
    "In classification taks, the input of classifier may rely on different features. Potentially, not all of these features are always observable. Thus, a soft sensor is required. Such a soft-sensor could be realised using a regressor.\n",
    "For such a scenario, the graphical pipeline is a natural fit since it enables the combination of different tasks in one pipeline.\n",
    "Note that in the current experimental state of the graphical pipeline, this use-case is not fully supported. However, we are working on this.\n",
    "\n",
    "\n",
    "### Content of this Notebook:\n",
    "* Understanding the API of graph pipelines\n",
    "* Examples of simple pipelines and how they can be implemented with graph pipelines.\n",
    "* More complex Grahpical Pipeline\n",
    "    * Forecasting\n",
    "* Grid Search with such a Graphical Pipeline\n",
    "\n",
    "### Credits\n",
    "The graphical pipeline was first developed by pyWATTS and was then adapted for sktime. The original implementation can be found [here](). pyWATTS is a open source library developed at the Institute of Applied Informatics and Automation at the KIT.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.datasets import load_arrow_head, load_longley, load_macroeconomic\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.compose import MultiplexForecaster, make_reduction\n",
    "from sktime.forecasting.model_selection import (\n",
    "    ForecastingGridSearchCV,\n",
    "    SlidingWindowSplitter,\n",
    "    temporal_train_test_split,\n",
    ")\n",
    "from sktime.forecasting.sarimax import SARIMAX\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_error\n",
    "from sktime.pipeline.pipeline import Pipeline\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sktime.transformations.series.detrend import Deseasonalizer, Detrender\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.exponent import ExponentTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to build a Graphical Pipeline\n",
    "The API of the graphical pipeline differs from the API of the standard pipeline. Instead of providing the full pipeline specification during the initialisation of the pipeline, the standard is to build the pipeline step by step.\n",
    "I.e.\n",
    "1. Create the pipeline object with `Pipeline()`\n",
    "2. Each step is added to the pipeline with the `add_step` method. The `add_step` method takes the following arguments:\n",
    "    * skobject: The sktime object that should be added to the pipeline\n",
    "    * name: The name of the step\n",
    "    * edges: A dictionary that specifies the edges of the graph. The keys of the dictionary are the input arguments of the sktime object and the values are the names of the steps that should be connected to the input argument.\n",
    "    * method: The method of the sktime object that should be called. If no method is specified, the default method would be inferred based on the added skobject. This parameter is used for the inverse_transform method.\n",
    "    * kwargs: Additional keyword arguments that should be passed to the sktime object.\n",
    "\n",
    "   E.g. `pipeline = pipeline.add_step(Differencer(), \"differencer\", edges={\"X\": \"y\"})` This would add a differencer to the pipeline.\n",
    "   Note that add_step does not vary pipeline, instead it returns a new pipeline object that contains the added step. Thus, you probably want to reassign the pipeline variable to the new pipeline object.\n",
    "\n",
    "In the following, we show a few simple Examples of the graphical pipeline, before we show more complex ones."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Examples\n",
    "### Forecasting Pipeline\n",
    "In the following, we show how a simple forecasting pipeline could be implemented using the graphical pipeline. The pipeline consists of the following steps:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "general_pipeline = Pipeline()\n",
    "differencer = Differencer()\n",
    "\n",
    "general_pipeline = general_pipeline.add_step(\n",
    "    differencer, \"differencer\", edges={\"X\": \"y\"}\n",
    ")\n",
    "general_pipeline = general_pipeline.add_step(\n",
    "    SARIMAX(), \"sarimax\", edges={\"X\": \"X\", \"y\": \"differencer\"}\n",
    ")\n",
    "general_pipeline = general_pipeline.add_step(\n",
    "    differencer, \"differencer_inv\", edges={\"X\": \"sarimax\"}, method=\"inverse_transform\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "1959    67213.735360\n1960    68328.076304\n1961    68737.861389\n1962    71322.894013\nFreq: A-DEC, Name: TOTEMP, dtype: float64"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = load_longley()\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y, X)\n",
    "\n",
    "general_pipeline.fit(y=y_train, X=X_train, fh=[1, 2, 3, 4])\n",
    "general_pipeline.predict(X=X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Alternative Way in Defining the Pipeline**\n",
    "An alternative to define a graphical pipeline would be to pass a list of steps to the Pipeline during creation. This would look as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "differencer = Differencer()\n",
    "\n",
    "general_pipeline = Pipeline(\n",
    "    [\n",
    "        {\"skobject\": differencer, \"name\": \"differencer\", \"edges\": {\"X\": \"y\"}},\n",
    "        {\n",
    "            \"skobject\": SARIMAX(),\n",
    "            \"name\": \"sarimax\",\n",
    "            \"edges\": {\"X\": \"X\", \"y\": \"differencer\"},\n",
    "        },\n",
    "        {\n",
    "            \"skobject\": differencer,\n",
    "            \"name\": \"differencer_inv\",\n",
    "            \"edges\": {\"X\": \"sarimax\"},\n",
    "            \"method\": \"inverse_transform\",\n",
    "        },\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification Pipeline\n",
    "In the following, we show how a simple classification pipeline could be implemented using the graphical pipeline. The pipeline consists of the following steps:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "general_pipeline = Pipeline()\n",
    "general_pipeline = general_pipeline.add_step(\n",
    "    ExponentTransformer(), \"exponent\", edges={\"X\": \"X\"}\n",
    ")\n",
    "general_pipeline = general_pipeline.add_step(\n",
    "    KNeighborsTimeSeriesClassifier(), \"classifier\", edges={\"X\": \"exponent\", \"y\": \"y\"}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['0', '1', '2', '0', '1', '2', '0', '1', '2', '0', '1', '2', '0',\n       '1', '2', '0', '1', '2', '0', '1', '2', '0', '1', '2', '0', '1',\n       '2', '0', '1', '2', '0', '1', '2', '0', '1', '2'], dtype='<U1')"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_arrow_head(split=\"train\", return_X_y=True)\n",
    "general_pipeline.fit(X=X, y=y)\n",
    "general_pipeline.predict(X=X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More Complex Examples with Grid Search\n",
    "The previous exemplary pipelines could be also easily built with the sequential implementations. Thus, in the following, we show a more complex pipeline that is only implementable as sequential pipeline with a lot of nesting. This makes it more difficult to apply a grid search to the pipeline.\n",
    "\n",
    "The considered use-case is to forecast the inflation using forecasts of the real gross domestic product, real disposable personal income, and the unemployment rate. Furthermore the unemployment rate is forecasted using the same features except the unemployment rate itself.\n",
    "The data is taken from the macrodata dataset from the statsmodels package.\n",
    "\n",
    "Thereby, we want to find the best combination of regressors for the different forecasts using either a Linear, Lasso, or Ridge Regression."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Pipeline Definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "pipeline = Pipeline()\n",
    "sklearn_scaler = StandardScaler()\n",
    "sktime_scaler = TabularToSeriesAdaptor(sklearn_scaler)\n",
    "deseasonalizer = Deseasonalizer(sp=4)\n",
    "detrender = Detrender()\n",
    "\n",
    "pipeline = pipeline.add_step(\n",
    "    sktime_scaler, name=\"scaler\", edges={\"X\": \"X__realgdp_realdpi_unemp\"}\n",
    ")\n",
    "pipeline = pipeline.add_step(\n",
    "    detrender, name=\"deseasonalizer\", edges={\"X\": \"X__realgdp_realdpi\"}\n",
    ")\n",
    "\n",
    "pipeline = pipeline.add_step(\n",
    "    MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    name=\"forecaster_gdp\",\n",
    "    edges={\"y\": \"deseasonalizer__realgdp\"},\n",
    ")\n",
    "\n",
    "pipeline = pipeline.add_step(\n",
    "    MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    name=\"forecaster_dpi\",\n",
    "    edges={\"y\": \"deseasonalizer__realdpi\"},\n",
    ")\n",
    "\n",
    "pipeline = pipeline.add_step(\n",
    "    MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    name=\"forecaster_unemp\",\n",
    "    edges={\n",
    "        \"y\": \"scaler__unemp\",\n",
    "        \"X\": [\n",
    "            \"forecaster_gdp\",\n",
    "            \"forecaster_dpi\",\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "\n",
    "pipeline = pipeline.add_step(\n",
    "    MultiplexForecaster(\n",
    "        [\n",
    "            (\n",
    "                \"ridge\",\n",
    "                make_reduction(Ridge(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "            (\n",
    "                \"lasso\",\n",
    "                make_reduction(Lasso(), windows_identical=False, window_length=5),\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    name=\"forecaster_inflation\",\n",
    "    edges={\"X\": [\"forecaster_dpi\", \"forecaster_unemp\"], \"y\": \"y\"},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "          realgdp  realdpi  unemp\nPeriod                           \n1959Q1   2710.349   1886.9    5.8\n1959Q2   2778.801   1919.7    5.1\n1959Q3   2775.488   1916.4    5.3\n1959Q4   2785.204   1931.3    5.6\n1960Q1   2847.699   1955.5    5.2\n...           ...      ...    ...\n2005Q3  12683.153   9308.0    5.0\n2005Q4  12748.699   9358.7    4.9\n2006Q1  12915.938   9533.8    4.7\n2006Q2  12962.462   9617.3    4.7\n2006Q3  12965.916   9662.5    4.7\n\n[191 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>realgdp</th>\n      <th>realdpi</th>\n      <th>unemp</th>\n    </tr>\n    <tr>\n      <th>Period</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1959Q1</th>\n      <td>2710.349</td>\n      <td>1886.9</td>\n      <td>5.8</td>\n    </tr>\n    <tr>\n      <th>1959Q2</th>\n      <td>2778.801</td>\n      <td>1919.7</td>\n      <td>5.1</td>\n    </tr>\n    <tr>\n      <th>1959Q3</th>\n      <td>2775.488</td>\n      <td>1916.4</td>\n      <td>5.3</td>\n    </tr>\n    <tr>\n      <th>1959Q4</th>\n      <td>2785.204</td>\n      <td>1931.3</td>\n      <td>5.6</td>\n    </tr>\n    <tr>\n      <th>1960Q1</th>\n      <td>2847.699</td>\n      <td>1955.5</td>\n      <td>5.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2005Q3</th>\n      <td>12683.153</td>\n      <td>9308.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2005Q4</th>\n      <td>12748.699</td>\n      <td>9358.7</td>\n      <td>4.9</td>\n    </tr>\n    <tr>\n      <th>2006Q1</th>\n      <td>12915.938</td>\n      <td>9533.8</td>\n      <td>4.7</td>\n    </tr>\n    <tr>\n      <th>2006Q2</th>\n      <td>12962.462</td>\n      <td>9617.3</td>\n      <td>4.7</td>\n    </tr>\n    <tr>\n      <th>2006Q3</th>\n      <td>12965.916</td>\n      <td>9662.5</td>\n      <td>4.7</td>\n    </tr>\n  </tbody>\n</table>\n<p>191 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_macroeconomic()\n",
    "\n",
    "X = data[[\"realgdp\", \"realdpi\", \"unemp\"]]\n",
    "y = data[[\"infl\"]]\n",
    "fh = ForecastingHorizon([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y, X=X, fh=fh)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "infl    18.041837\ndtype: float64"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(y=y_train, X=X_train, fh=fh)\n",
    "result = pipeline.predict(X=None, fh=y_test.index)\n",
    "((result - y_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "infl    19.608558\ndtype: float64"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = make_reduction(Ridge(), windows_identical=False, window_length=5)\n",
    "ridge.fit(y=y_train, fh=fh)\n",
    "((ridge.predict() - y_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Grid Search\n",
    "\n",
    "This pipeline has multiple parameters that might be tested to find the configurations. These parameters include:\n",
    "* which forecaster should be used for which variable\n",
    "* what should be the hyperparameters of the forecaster\n",
    "* what should be the preprocessing looks like for the different forecaster\n",
    "* which features should be used for the different forecasters\n",
    "* ...\n",
    "\n",
    "Doing this manually is really annoying, thus hyperparameter searches exist. E.g. ForecastingGridSearchCV in sktime.\n",
    "Since the graphical pipeline performs a forecasting task, we use this grid search to find the best configuration.\n",
    "Therefore, we have to specify a paramter grid that contains the different configurations that should be tested.\n",
    "The parameter grid is a dictionary that contains the different parameters that should be tested. The keys of the dictionary are the names of the steps in the pipeline and the values are the different configurations that should be tested for the step. Thus, to change the parameters of a skobject in the pipeline the key looks like: `step_name__skobject_name__parameter_name`. To change the inputs you need to vary the edges. This can be done with keys following the following scheme: `step_name_edges_Xory`\n",
    "\n",
    "In the following, we initialise the gridsearch and perform a hyperparameter search."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.336e+03, tolerance: 2.727e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\bi4372\\.conda\\envs\\pyWATTS-deRSE-2023\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.676e+03, tolerance: 2.996e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "grid = ForecastingGridSearchCV(\n",
    "    pipeline,\n",
    "    cv=SlidingWindowSplitter(\n",
    "        window_length=len(X_train) - 20,\n",
    "        step_length=4,\n",
    "        fh=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    ),\n",
    "    scoring=mean_absolute_error,\n",
    "    # refit=False,\n",
    "    error_score=\"raise\",\n",
    "    param_grid={\n",
    "        \"forecaster_inflation__skobject__selected_forecaster\": [\"ridge\", \"lasso\"],\n",
    "        \"forecaster_unemp__skobject__selected_forecaster\": [\"ridge\", \"lasso\"],\n",
    "        \"forecaster_dpi__skobject__selected_forecaster\": [\"ridge\", \"lasso\"],\n",
    "        \"forecaster_gdp__skobject__selected_forecaster\": [\"ridge\", \"lasso\"],\n",
    "        \"forecaster_inflation__edges__X\": [\n",
    "            [\"forecaster_unemp\"],\n",
    "            [\"forecaster_unemp\", \"forecaster_dpi\"],\n",
    "        ],\n",
    "        \"forecaster_unemp__edges__X\": [\n",
    "            [],\n",
    "            [\"forecaster_dpi\"],\n",
    "            [\"forecaster_gdp\", \"forecaster_dpi\"],\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "grid.fit(y=y_train, X=X_train)\n",
    "result = grid.predict(X=None, fh=y_test.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_test__DynamicForecastingErrorMetric  mean_fit_time  mean_pred_time  \\\n0                                   1.539329       0.093885        0.053009   \n1                                   1.720565       0.082869        0.049055   \n2                                   1.311031       0.366696        0.160758   \n3                                   3.116475       0.183237        0.085956   \n4                                   1.851588       0.171509        0.089728   \n..                                       ...            ...             ...   \n91                                  1.443361       0.076905        0.037015   \n92                                  1.443361       0.079046        0.041127   \n93                                  1.443361       0.081455        0.040803   \n94                                  1.443361       0.108554        0.060533   \n95                                  1.443361       0.137029        0.073225   \n\n                                               params  \\\n0   {'forecaster_dpi__skobject__selected_forecaste...   \n1   {'forecaster_dpi__skobject__selected_forecaste...   \n2   {'forecaster_dpi__skobject__selected_forecaste...   \n3   {'forecaster_dpi__skobject__selected_forecaste...   \n4   {'forecaster_dpi__skobject__selected_forecaste...   \n..                                                ...   \n91  {'forecaster_dpi__skobject__selected_forecaste...   \n92  {'forecaster_dpi__skobject__selected_forecaste...   \n93  {'forecaster_dpi__skobject__selected_forecaste...   \n94  {'forecaster_dpi__skobject__selected_forecaste...   \n95  {'forecaster_dpi__skobject__selected_forecaste...   \n\n    rank_test__DynamicForecastingErrorMetric  \n0                                       54.5  \n1                                       58.5  \n2                                        1.5  \n3                                       95.5  \n4                                       65.0  \n..                                       ...  \n91                                      46.5  \n92                                      46.5  \n93                                      46.5  \n94                                      46.5  \n95                                      46.5  \n\n[96 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_test__DynamicForecastingErrorMetric</th>\n      <th>mean_fit_time</th>\n      <th>mean_pred_time</th>\n      <th>params</th>\n      <th>rank_test__DynamicForecastingErrorMetric</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.539329</td>\n      <td>0.093885</td>\n      <td>0.053009</td>\n      <td>{'forecaster_dpi__skobject__selected_forecaste...</td>\n      <td>54.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.720565</td>\n      <td>0.082869</td>\n      <td>0.049055</td>\n      <td>{'forecaster_dpi__skobject__selected_forecaste...</td>\n      <td>58.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.311031</td>\n      <td>0.366696</td>\n      <td>0.160758</td>\n      <td>{'forecaster_dpi__skobject__selected_forecaste...</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.116475</td>\n      <td>0.183237</td>\n      <td>0.085956</td>\n      <td>{'forecaster_dpi__skobject__selected_forecaste...</td>\n      <td>95.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.851588</td>\n      <td>0.171509</td>\n      <td>0.089728</td>\n      <td>{'forecaster_dpi__skobject__selected_forecaste...</td>\n      <td>65.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>1.443361</td>\n      <td>0.076905</td>\n      <td>0.037015</td>\n      <td>{'forecaster_dpi__skobject__selected_forecaste...</td>\n      <td>46.5</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>1.443361</td>\n      <td>0.079046</td>\n      <td>0.041127</td>\n      <td>{'forecaster_dpi__skobject__selected_forecaste...</td>\n      <td>46.5</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>1.443361</td>\n      <td>0.081455</td>\n      <td>0.040803</td>\n      <td>{'forecaster_dpi__skobject__selected_forecaste...</td>\n      <td>46.5</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>1.443361</td>\n      <td>0.108554</td>\n      <td>0.060533</td>\n      <td>{'forecaster_dpi__skobject__selected_forecaste...</td>\n      <td>46.5</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>1.443361</td>\n      <td>0.137029</td>\n      <td>0.073225</td>\n      <td>{'forecaster_dpi__skobject__selected_forecaste...</td>\n      <td>46.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>96 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "infl    19.244087\ndtype: float64"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((result - y_test) ** 2).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "{'forecaster_dpi__skobject__selected_forecaster': 'ridge',\n 'forecaster_gdp__skobject__selected_forecaster': 'ridge',\n 'forecaster_inflation__edges__X': ['forecaster_unemp'],\n 'forecaster_inflation__skobject__selected_forecaster': 'ridge',\n 'forecaster_unemp__edges__X': ['forecaster_dpi'],\n 'forecaster_unemp__skobject__selected_forecaster': 'ridge'}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "1.3110312019415922"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
